\documentclass[a4wide, 11pt]{article}
\usepackage{a4, fullpage}
\setlength{\parskip}{0.4cm}
\setlength{\parindent}{0cm}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{float}
\usepackage[margin=1cm]{caption}

\begin{document}

\title{MAlice Report}

\author{Thomas Rooney and Alex Rozanski}

\date{\today}

\maketitle

\section{Our Compiler}

One of the parts of our compiler that we feel is most useful is the syntactic and semantic error annotations. We were heavily inspired by clang's error messages in this regard, and display an ASCII `$\wedge$' character to `point' to the locations of such syntactic errors as missing tokens, and the tilde character to `underline' larger expressions, such as operands to a mathematical operator. This can be seen in the following example:

\begin{verbatim}
Semantic error (Line 6): Cannot match type `number' with expected types `boolean' for
operand `10' over operator &&.
    x became 10 && 20.
             ~~ ^^  
\end{verbatim}

\subsection{Extensibility}

- ANTLR grammar.
- Visitor pattern.
- Separation of validation and code generation stages. Some duplication though.
- Performance issues: Building the symbol table twice. Reflection and RTTI (slow!).


\subsection{Rigi}

\subsection{Benchmarks}

In building our compiler we also constructed an autotester. As part of this autotester, we construct benchmarks on the average time to process a file vs the average time it takes the reference compiler to process a file. This can be seen in `autotest.h' - where it shows that we, on average, are over ten times faster than the reference compiler for all of the given examples.
\begin{verbatim}
Average Time of Reference Compiler / Average Time of Our Compiler: 10.81822
\end{verbatim}

\subsection{Our Extension}

For our extension, we took the principle that a language isn't complete until it can be effectively debugged. Rather than go for a full route of building up a debugging infrastructure however, we decided to build in metadata such that compiled Alice files can be debugged using existing debuggers which support the DWARF debugging format. This includes both gdb and lldb.

The end result of this extension is that a compiled alice file can be debugged in gdb. Breakpoints can be set in the .alice code, variables can be printed and code can be stepped through line by line. To activate, pass the `-g' flag to the compile executable.

\begin{verbatim}
(gdb) break 5
Breakpoint 1 at 0x40056c: file ../malice_examples/valid/fibonacciIterative.alice, line 5.
(gdb) run
Starting program: /vol/bitbucket/tr111/malice_examples/valid/fibonacciIterative 
Which term in the Fibonacci sequence shall I compute?10

Breakpoint 1, fibonacci ()
    at ../malice_examples/valid/fibonacciIterative.alice:5
5     i became 0.
....
(gdb) next
8         temp was a number and temp became fib0.
(gdb) next
9         fib0 became fib1.
(gdb) print fib0
$2 = 0
(gdb) print fib1
$3 = 1
(gdb) next
10        fib1 became temp + fib1.
(gdb) print fib0
$4 = 1
\end{verbatim}


\section{Design Choices}

- Evaluation of using C++. Gives us more control and is more performant, but lower-level.
;
When we embarked on this project we both had the view that what we produced had to be as close as possible to what we would do, should we have to perform a similar task commercially but of greater complexity. As such, we built up a product around the idea of extensibility and ease of development. We tried to maximise the use of tools and have a simple, easily understandable design.

For our initial lexing and parsing stages, we decided to use ANTLR. It is a well-established tool which has the advantage of a GUI for editing and debugging which makes the development process much smoother - being able to see the parsing stages and AST generation step-by-step was incredibly useful when things went wrong. ANTLR can generate code for multiple languages, and although we had decided to use C++ for our compiler, we used the backend which generated a C lexer and parser from our BNF. We made this decision based on some preliminary research which suggested that the backend producing C++ code was less complete. 

Disadvantages of using ANTLR include the fact that sometimes the lexer errors produced were not very informative, and were missing vital information such as line or column numbers, and we had little or no control over this. The ANTLR-produced AST was also very rigid, which made it very difficult to modify the tree directly through optimisation, which was our initial plan.

The second major decision that we made was in the use of the LLVM C++ backend for the code generation stage, where we use LLVM functions to generate a tree of constructs for the different statements in LLVM IR (instructions such as \texttt{load} and \texttt{store} and function and variable declarations). We made this decision based on the fact that it seemed very well-documented at the time, and this would make adding extra features easier; once we had LLVM classes set up correctly, it is simple to activate the other LLVM libraries that add extra features into production compilers.

For example, in our final steps where we move code from LLVM classes into LLVM IR, we can retarget our compiler at any particular architecture that LLVM has support for. In fact, when we generate code, we pull the targeting information from the host system directly, and generate compilable code for that particular processor. If our compiler was run on, for example, an ARM processor, it wouldn't generate x86 assembler but ARM assembler - a massive advantage over focusing on a particular architecture.

One of the major disadvantages of this approach was the lack of reference material in using the C++ backend. At times it seemed like everything was going well, but in fact bits of the backend hadn't been implemented yet. From our experience using the libraries directly, it seems like while the majority of it is very generic, there are sections of the code base that are very specific to those few projects that use LLVM directly (like clang). It seems like it was only partially implemented in places such that Ð for example Ð clang generates code correctly, but the moment you call a function differently to the code in clang, output code is incorrectly generated.

An example of this is in the debug information for functions. Clang uses \texttt{llvm::DIType()} to denote an unknown or \texttt{void} return type for the function, and this works correctly, should the linkage and function names be the same. However, The moment they are different (debug name `hatta' and linkage name `main'), \texttt{!loc 0 0 0} is placed as a header of the function (in x86 Asm). This tries to set the debugger's current line number information to \texttt{[Null, Line 0, Col 0]}, an error that blocks compilation. We solved this problem by generating a \texttt{llvm::DISubroutineType} of \texttt{void}, with size/alignment/encoding \texttt{0} instead of the default \texttt{llvm::DIType()}. 

\section{Beyond the Specification}

- Interpreter.
- Language extensions - object-orientation and dynamic memory allocation.
- Disassembly to MAlice. 


\end{document}
